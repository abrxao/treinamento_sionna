{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "gpu_num = 0 # Use \"\" para usar a CPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# O Colab atualmente não suporta a versão mais recente do ipython.\n",
    "# Portanto, a pré-visualização não funciona no Colab. No entanto, sempre que possível,\n",
    "# recomendamos fortemente usar o modo de pré-visualização da cena.\n",
    "\n",
    "low_resolution = [360,240] # aumente para obter maior qualidade de renderização\n",
    "medium_resolution = [560,420]\n",
    "high_resolution = [800,600]\n",
    "\n",
    "# Configurar o notebook para usar apenas uma GPU e alocar apenas a quantidade de memória necessária\n",
    "# Para mais detalhes, veja https://www.tensorflow.org/guide/gpu\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "# Evitar avisos do TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "print(tf.__version__)\n",
    "tf.random.set_seed(1) # Definir uma semente global para a aleatoriedade, garantindo reprodutibilidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "    \n",
    "from sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, Camera\n",
    "from sionna.channel import subcarrier_frequencies, cir_to_ofdm_channel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "import ast\n",
    "# Read the Excel file\n",
    "df = pd.read_excel('output_new_scene.xlsx')\n",
    "\n",
    "# Extract the desired columns\n",
    "desired_columns = ['vehid','steps', 'coord']\n",
    "df = df[desired_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pega os ids dos veiculos\n",
    "unique_vehids = df['vehid'].unique()\n",
    "#Pega o maior e o menor valor da coluna steps para saber qual a duração da simulação dentro do SUMO\n",
    "max_steps = df['steps'].max()\n",
    "min_steps = df['steps'].min()\n",
    "simulation_duration = max_steps - min_steps + 1\n",
    "\n",
    "# Array que receberá os objetos com as informações dos veiculos\n",
    "vehicles = []\n",
    "# Seleciona o primeiro veiculo para guardar os valores do primeiro e o último step em que ele aparece\n",
    "vehid_df = df[df['vehid'] == unique_vehids[0]]\n",
    "max_first_apper = vehid_df['steps'].iloc[0]\n",
    "min_last_apper = vehid_df['steps'].iloc[-1]\n",
    "\n",
    "#Esse loop será responsável por encontrar o último step em que um veiculo aparece e o primeiro step em que um veiculo desaparece. Esses valores serão usados para cortar a simulação no SUMO e evitar que o Sionna tente renderizar um veiculo que não está mais na simulação.\n",
    "for vehid in unique_vehids:\n",
    "    vehid_df = df[df['vehid'] == vehid]\n",
    "    # Acha o primeiro Step em que o carro é rendezirado\n",
    "    first_apper = vehid_df['steps'].iloc[0]\n",
    "    # Acha o ultimo Step em que o carro é rendezirado\n",
    "    last_apper = vehid_df['steps'].iloc[-1]\n",
    "    # Atualiza o primeiro e o ultimo step em que um veiculo aparece\n",
    "    if first_apper > max_first_apper:\n",
    "        max_first_apper = first_apper\n",
    "    if last_apper < min_last_apper:\n",
    "        min_last_apper = last_apper\n",
    "# Corta o dataframe para que ele contenha apenas os veiculos que aparecem em todos os steps\n",
    "df = df[df['steps'] >= max_first_apper]\n",
    "df = df[df['steps'] <= min_last_apper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "subcarrier_spacing = 60e3\n",
    "# Number of used subcarriers \n",
    "num_used_subcarriers = 66*12\n",
    "# Numero de RBs * 12 subcarriers\n",
    "# Numero de RBs é tabelado, ver link abaixo:\n",
    "# https://www.nrexplained.com/bandwidth\n",
    "# 47.52MHz de banda\n",
    "\n",
    "num_ofdm_symbols = 14 + 1 # 14 OFDM symbols + 1 de guarda\n",
    "\n",
    "#Carrier Frequency\n",
    "# 28GHz Por padrão da cena do sionna (e também do fr1(Frequency Range 1 - 3gpp) do 5G)\n",
    "central_frequency = 28e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo de cada RB dada as configurações anteriores 0.25 ms\n",
      "Número de passos por segundo é de 400 passos\n"
     ]
    }
   ],
   "source": [
    "# Devido a escolha\n",
    "rb_interval = num_ofdm_symbols * 1/subcarrier_spacing # Em segundos\n",
    "rb_interval = rb_interval * 1e3 # Em milisegundos\n",
    "print(\"Tempo de cada RB dada as configurações anteriores\",rb_interval, \"ms\")\n",
    "\n",
    "# Intervalo em TTI de cada passo da simulação\n",
    "num_of_TTIs = 10 # em TTI\n",
    "\n",
    "# Calculando o valores de passos necessarios para ter uma resolução desejada\n",
    "interpolate_steps = int(1/(rb_interval*1e-3*num_of_TTIs))\n",
    "print(f\"Número de passos por segundo é de {interpolate_steps} passos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop percorrendo cada veiculo para montar o objeto com as informacoes\n",
    "\n",
    "for vehid in unique_vehids:\n",
    "    coords=[]\n",
    "    vehid_df = df[df['vehid'] == vehid]\n",
    "    coords_list = vehid_df['coord'].tolist()\n",
    "    \n",
    "    #Transforma a lista de strings em uma lista de tuplas\n",
    "    coords = [ast.literal_eval(elem) for elem in coords_list]\n",
    "    x, y = zip(*coords)\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Cria uma função de interpolação linear para\n",
    "    f = interp1d(x, y)\n",
    "    \n",
    "    # Generate new x values: since we want 4000 new points between each pair, calculate the new step\n",
    "    new_x = np.linspace(x.min(), x.max(), num=len(x) + interpolate_steps * (len(x) - 1))\n",
    "\n",
    "    # Use the interpolation function to generate new y values\n",
    "    new_y = f(new_x)\n",
    "    obj = {\n",
    "        'vehid': vehid,\n",
    "        'first_apper': first_apper,\n",
    "        'last_apper':last_apper,\n",
    "        'coords': list(zip(new_x, new_y)),\n",
    "    }\n",
    "    vehicles.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = load_scene(\"./scenes/bm_v2/scene.xml\")\n",
    "#-38.49168,-3.72718,-38.48401,-3.72205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a frequência central da cena\n",
    "scene.frequency = central_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um vetor com as frequências dos subportadores\n",
    "frequencies = subcarrier_frequencies(num_used_subcarriers, subcarrier_spacing) + scene.frequency\n",
    "# Reduz o número de frequências para o número de subportadores usados para um limite aceitável\n",
    "frequencies = frequencies[6::12]\n",
    "\n",
    "# Esse valores são referentes ao cruzamento entre uma posição de referencia do sumo e da cena no blender\n",
    "x_diff,y_diff = [421.55, 282.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene.tx_array = PlanarArray(\n",
    "                                num_rows=4,\n",
    "                                num_cols=4,\n",
    "                                vertical_spacing=0.5,\n",
    "                                horizontal_spacing=0.5,\n",
    "                                pattern=\"tr38901\",\n",
    "                                polarization=\"V\"\n",
    "                            )\n",
    "scene.rx_array = PlanarArray(\n",
    "                                num_rows=1,\n",
    "                                num_cols=1,\n",
    "                                vertical_spacing=0.5,\n",
    "                                horizontal_spacing=0.5,\n",
    "                                pattern=\"iso\",\n",
    "                                polarization=\"V\"\n",
    "                            )\n",
    "\n",
    "tx_1 = Transmitter(\"tx_1\", [-314, -82, 65], [0.0, 0.0, 0.0])\n",
    "tx_2 = Transmitter(\"tx_2\", [7, 117, 8], [0.0, 0.0, 0.0])\n",
    "scene.add(tx_1)\n",
    "scene.add(tx_2)\n",
    "#tx = Transmitter(\"tx\", [-262, 192, 65], [0.0, 0.0, 0.0])\n",
    "#scene.add(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tempo total da simulação é de 7 segundos\n"
     ]
    }
   ],
   "source": [
    "total_time = min_last_apper - max_first_apper\n",
    "print(f\"O tempo total da simulação é de {total_time} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_simulate = 0.1 # Tempo de simulação em segundos\n",
    "steps_to_simulate = int(time_to_simulate * interpolate_steps) # Número de passos a simular\n",
    "shift_time = 1 # Tempo em segundos para deslocar a simulação\n",
    "shift_steps_interpol= int(shift_time * interpolate_steps) # Número de passos a deslocar\n",
    "\n",
    "total_steps_interpol = shift_steps_interpol + steps_to_simulate # Número total de passos que vão ser simulados\n",
    "\n",
    "# Filtra o intervalo no dataframe para pegar apenas os passos que serão simulados\n",
    "for vehicle in vehicles: \n",
    "    vehicle['coords'] = np.array(vehicle['coords'][shift_steps_interpol:total_steps_interpol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Inicializa h_simulate como um tensor vazio\n",
    "h_simulate = None\n",
    "\n",
    "for interpol_step in range(steps_to_simulate):\n",
    "    for freq_index, veh in enumerate(vehicles):\n",
    "        # Pega as coordenadas do veículo\n",
    "        x1, y1 = veh['coords'][interpol_step]\n",
    "        # Valores que eu calculo para a cena diff do sumo\n",
    "        x1, y1 = x1 - x_diff, y1 - y_diff\n",
    "        # Adiciona o veículo na cena caso seja o seu primeiro step\n",
    "        if interpol_step == 41:\n",
    "            scene.add(Receiver(name=veh[\"vehid\"], position=[x1, y1, 1.5]))\n",
    "        else:\n",
    "            scene.receivers[veh[\"vehid\"]].position = [x1, y1, 1.5]\n",
    "\n",
    "    paths = scene.compute_paths(diffraction=True)\n",
    "    paths.normalize_delays = False\n",
    "    \n",
    "    # Calculando o CIR para o usuário e o delay dos caminhos\n",
    "    a, tau = paths.cir()\n",
    "    \n",
    "    # Seleciona o índice do batch e do time step\n",
    "    batch_index = 0\n",
    "    time_step_index = 0\n",
    "    h_new = cir_to_ofdm_channel(frequencies, a, tau)[batch_index, :, 0, :, :, time_step_index]\n",
    "    \n",
    "    # Adiciona uma nova dimensão e concatena\n",
    "    if h_simulate is None:\n",
    "        h_simulate = np.expand_dims(h_new, axis=0)\n",
    "    else:\n",
    "        h_new_expanded = np.expand_dims(h_new, axis=0)\n",
    "        h_simulate = np.concatenate((h_simulate, h_new_expanded), axis=0)\n",
    "\n",
    "# Agora h_simulate é um tensor com uma nova dimensão para cada interpol_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimensiona h_simulate para as novas dimensões\n",
    "h_simulate_reshaped = np.transpose(h_simulate, (4, 1, 0, 3, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(\"coordinates.h5\", mode=\"w\") as f:\n",
    "    f.attrs[\"UE Names\"] = list(unique_vehids)\n",
    "    f.attrs[\"BS Names\"] = list(scene.transmitters.keys())\n",
    "    f.attrs[\"Time interval\"] = rb_interval*num_of_TTIs*1e-3 # Em segundos\n",
    "    for vehicle in vehicles:\n",
    "        x, y = zip(*vehicle[\"coords\"])\n",
    "        x = np.array(x)\n",
    "        x = x - x_diff\n",
    "        y = np.array(y)\n",
    "        y = y - y_diff\n",
    "        ue_name = vehicle['vehid']\n",
    "        z = np.linspace(1.5,1.5,len(x))\n",
    "        df_coords = pd.DataFrame({\"x\": x, \"y\": y, \"z\": z})\n",
    "        \n",
    "        f.create_dataset(f\"{ue_name}_coordinates\", data=df_coords.to_records(index=False))\n",
    "        \n",
    "    for tx in scene.transmitters.keys():\n",
    "        tx_position = np.array(scene.transmitters[tx].position)\n",
    "        bs_position = pd.DataFrame({\"x\": [tx_position[0]], \"y\": [tx_position[1]], \"z\": [tx_position[2]]})\n",
    "        f.create_dataset(f\"BS_coordinate_{tx}\", data=bs_position.to_records(index=False).reshape(()))\n",
    "\n",
    "    f.attrs[\"minX\"] = -scene.size[0]/2\n",
    "    f.attrs[\"maxX\"] = scene.size[0]/2\n",
    "    f.attrs[\"minY\"] = -scene.size[1]/2\n",
    "    f.attrs[\"maxY\"] = scene.size[1]/2\n",
    "    \n",
    "    num_of_ue_antennas = len(scene.transmitters.keys())\n",
    "    channel_dataset = f.create_group('BS Channels to')\n",
    "    channel_dataset.attrs[\"Frequencies\"] = frequencies\n",
    "    \n",
    "    for freq_index in range(len(frequencies)):\n",
    "        freq_group = channel_dataset.create_group(f'Freq{freq_index}')\n",
    "        for veh_index in range(len(vehicles)):\n",
    "            veh_name = vehicles[veh_index]['vehid']\n",
    "            veh_group = freq_group.create_group(veh_name)\n",
    "            veh_group.create_dataset('h', data=h_simulate_reshaped[freq_index,veh_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sionnasim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad6279602125e112656d6b2387c08178a266d79c39b56ca3ffdb73958bcfe64f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
